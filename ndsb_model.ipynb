{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''CNN layers from Keras'''\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Activation, Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THEANO_FLAGS='floatX=float32,device=gpu0,lib.cnmem=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.load(\"X_denoised.npy\")\n",
    "y = np.load(\"y_train.npy\")\n",
    "X[0,0,0,:]\n",
    "y[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Not required. Loaded the denoised images \n",
    "X = np.load(\"X_train.npy\")\n",
    "y = np.load(\"y_train.npy\")\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "X = X/255\n",
    "#Denoise the images - basic denoising using total variation method\n",
    "status = Progbar(X.shape[0])\n",
    "print(\"Denoising the images\")\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        X[i,j,:,:] = denoise_bilateral(X[i,j,:,:], sigma_range=0.05, sigma_spatial=15)\n",
    "    status.add(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Load train.npy file - images stored as numpy array'''\n",
    "def split_data(X, y, split_ratio = 0.85): \n",
    "    #X = preprocess(X)\n",
    "    sam = np.random.rand(y.shape[0]) < split_ratio\n",
    "    X_train = X[sam,:,:,:]\n",
    "    X_test = X[~sam, :,:,:]\n",
    "    y_train = y[sam,:]\n",
    "    y_test = y[~sam,:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''random Rotation in every iteration'''\n",
    "def rotation(X, angle_range):\n",
    "    print(\"rotation augmentation\")\n",
    "    status = Progbar(X.shape[0])\n",
    "    X_rotated = np.copy(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        angle = np.random.randint(-angle_range, angle_range)\n",
    "        for j in range(X.shape[1]):\n",
    "            X_rotated[i,j,:,:] = ndimage.rotate(X[i,j,:,:], angle, reshape=False, order=2)\n",
    "        status.add(1)\n",
    "    \n",
    "    return X_rotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Random shifting in every iteration- to make the fit tolerant with unseen test data'''\n",
    "def shift_random(X, h_range, v_range):\n",
    "    X_shift = np.copy(X)\n",
    "    print(\"random shifting\")\n",
    "    status = Progbar(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        h_shift = np.random.rand() * h_range * 2 - h_range\n",
    "        v_shift = np.random.rand() * v_range * 2 - v_range\n",
    "        h_shift = int(h_shift * X.shape[2])\n",
    "        v_shift = int(v_shift * X.shape[3])\n",
    "        for j in range(X.shape[1]):\n",
    "            X_shift[i,j,:,:] = ndimage.shift(X[i,j,:,:], (h_shift, v_shift), order = 0)\n",
    "        status.add(1)\n",
    "\n",
    "    return X_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_rmse(y, y_hat):\n",
    "    return K.sqrt(K.mean(K.square(y-y_hat), axis = -1))\n",
    "\n",
    "def normalize(x):\n",
    "    return (x-K.mean(x))/K.std(x)\n",
    "\n",
    "def get_model():\n",
    "    #input layer\n",
    "    model = Sequential()\n",
    "    model.add(Activation(activation= normalize, input_shape = (30,64,64)))\n",
    "    \n",
    "    #1st hidden layer - convolutional\n",
    "    model.add(Convolution2D(64,3,3, border_mode = \"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Convolution2D(64,3,3, border_mode= \"valid\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #2nd Hidden layer - Convolutional\n",
    "    model.add(Convolution2D(96,3,3, border_mode = \"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Convolution2D(96,3,3, border_mode= \"valid\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #3rd Hidden layer - Convolutional\n",
    "    model.add(Convolution2D(128,3,3, border_mode = \"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Convolution2D(128,3,3, border_mode= \"valid\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    #model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides= (2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #final layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, W_regularizer=l2(1e-3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    #output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    adam = Adam(lr=1e-4)\n",
    "    model.compile(optimizer = adam, loss = my_rmse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_crps(y, yhat):\n",
    "    return np.sum(np.square(y-yhat))/len(y)\n",
    "\n",
    "def get_cdf(x, std = 1e-08):\n",
    "    x_cdf = np.zeros((x.shape[0], 600))\n",
    "    for i in range(x.shape[0]):\n",
    "        x_cdf[i] = norm.cdf(range(600), x[i], std)\n",
    "    return x_cdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs_iteration = 1\n",
    "iterations = 1\n",
    "batch_size = 64\n",
    "crps = 1\n",
    "\n",
    "min_systole_val_loss = float(\"inf\")\n",
    "min_diastole_val_loss = float(\"inf\")\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(\"----- starting iteration %d -----------\" %(i+1))\n",
    "    #Split the data\n",
    "    X_train, y_train, X_test, y_test = split_data(X, y, 0.85)\n",
    "    #Get defined CNN model\n",
    "    systole_model = get_model()\n",
    "    diastole_model = get_model()\n",
    "\n",
    "    #For every iteration we will augment train data with random rotations and shifting to make our model\n",
    "    #tolerant to unseen test data\n",
    "    X_train_rs = rotation(X_train, angle_range=15)\n",
    "    X_train_rs = shift_random(X_train_rs, 0.1, 0.1)\n",
    "\n",
    "    #Fit the model for systole and diastole volumes\n",
    "    fit_systole = systole_model.fit(X_train_rs, y_train[:,0], \n",
    "                      nb_epoch= epochs_iteration, batch_size= batch_size,\n",
    "                      validation_data = (X_test, y_test[:,0]),\n",
    "                      shuffle=True, verbose=1)\n",
    "\n",
    "    fit_diastole = diastole_model.fit(X_train_rs, y_train[:,1], \n",
    "                      nb_epoch=epochs_iteration, batch_size=batch_size,\n",
    "                      validation_data = (X_test, y_test[:,1]),\n",
    "                      shuffle=True, verbose=1)\n",
    "\n",
    "\n",
    "    #can be used as standard deviations in computing cdf for predicted volumes\n",
    "    systole_tr_loss = fit_systole.history[\"loss\"][-1]\n",
    "    systole_val_loss = fit_systole.history[\"val_loss\"][-1]\n",
    "    diastole_tr_loss = fit_diastole.history[\"loss\"][-1]\n",
    "    diastole_val_loss = fit_diastole.history[\"val_loss\"][-1]\n",
    "\n",
    "    if i % crps == 0:\n",
    "        #To validate augmentation effect\n",
    "        systole_tr_pred = systole_model.predict(X_train, batch_size=batch_size, verbose=1)\n",
    "        systole_val_pred = systole_model.predict(X_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "        diastole_tr_pred = diastole_model.predict(X_train, batch_size=batch_size, verbose=1)\n",
    "        diastole_val_pred = diastole_model.predict(X_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "        '''Now get \"cdf\"s of actual volumes for train and test'''\n",
    "        tr_cdf = get_cdf(np.concatenate((y_train[:,0], y_train[:,1])))\n",
    "        val_cdf = get_cdf(np.concatenate((y_test[:,0], y_test[:,1])))\n",
    "\n",
    "        '''Get cdf s of predicted volumes of train and test'''\n",
    "        tr_pred_cdf = get_cdf(np.concatenate((systole_tr_pred, diastole_tr_pred)), np.mean((systole_tr_loss, diastole_tr_loss)))\n",
    "        val_pred_cdf = get_cdf(np.concatenate((systole_val_pred, diastole_val_pred)), np.mean((systole_val_loss, diastole_val_loss)))\n",
    "\n",
    "        '''Now calculate crps = continuous ranked probability score for train and test'''\n",
    "        crps_train = get_crps(tr_cdf, tr_pred_cdf)\n",
    "        crps_test = get_crps(val_cdf, val_pred_cdf)\n",
    "\n",
    "        print(\"crps of train is %.4f on iteration %d\" %(crps_train, i+1))\n",
    "        print(\"crps of test is %.4f on iteration %d\" %(crps_test, i+1))\n",
    "\n",
    "    if systole_val_loss < min_systole_val_loss:\n",
    "        #save weights\n",
    "        min_systole_val_loss = systole_val_loss\n",
    "        systole_model.save_weights(\"weights_systole.hdf5\", overwrite = True)\n",
    "\n",
    "    if diastole_val_loss < min_diastole_val_loss:\n",
    "        #save weights\n",
    "        min_diastole_val_loss = diastole_val_loss\n",
    "        diastole_model.save_weights(\"weights_diastole.hdf5\", overwrite = True)\n",
    "\n",
    "    '''Save val_losses which are required as std deviations for generating submission file'''\n",
    "    with open(\"val_losses.txt\", mode = \"wb\") as f:\n",
    "        f.write(str(min_systole_val_loss))\n",
    "        f.write(\" \")\n",
    "        f.write(str(min_diastole_val_loss))\n",
    "        print(\"best weights and min losses saved for iteration %d\" %(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = X_sub[19,20,:,:]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "status = Progbar(img.shape[0])\n",
    "img = X[0,:,:,:]\n",
    "img_d = np.copy(img)\n",
    "print(\"Denoising the images\")\n",
    "\n",
    "for j in range(img.shape[0]):\n",
    "    img_d[j,:,:] = denoise_bilateral(img[j,:,:], sigma_range=0.05, sigma_spatial=15)\n",
    "    status.add(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load test data for submission\n",
    "X_sub = np.load(\"X_validation.npy\") #load test data for submission\n",
    "ids = range(501,701) #Patient ids\n",
    "\n",
    "X_sub = X_sub.astype(\"float32\")\n",
    "X_sub = X_sub/255\n",
    "X_sub_denoised = np.copy(X_sub)\n",
    "#Denoise the images - basic denoising using total variation method\n",
    "status = Progbar(X_sub.shape[0])\n",
    "print(\"Denoising the images\")\n",
    "for i in range(X_sub.shape[0]):\n",
    "    for j in range(X_sub.shape[1]):\n",
    "        X_sub_denoised[i,j,:,:] = denoise_bilateral(X_sub[i,j,:,:], sigma_range=0.05, sigma_spatial=15)\n",
    "    status.add(1)\n",
    "\n",
    "np.save(\"X_sub_denoised.npy\", X_sub_denoised)\n",
    "print(\"Saved successfully denoised submission data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accumulate_studies(ids,cdf):\n",
    "    \n",
    "    count = {}\n",
    "    accum = {}\n",
    "    size = cdf.shape[0]\n",
    "    for i in range(size):\n",
    "        study_id = ids[i]\n",
    "        idx = int(study_id)\n",
    "        if idx not in count:\n",
    "            count[idx] = 0\n",
    "            accum[idx] = np.zeros((1, cdf.shape[1]), dtype = np.float32)\n",
    "        count[idx] += 1\n",
    "        accum[idx] += cdf[i,:]\n",
    "    for i in count.keys():\n",
    "        accum[i][:] /= count[i]\n",
    "    return accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_sub_denoised = np.load(\"X_sub_denoised.npy\")\n",
    "ids = np.load(\"ids_validate.npy\")\n",
    "#loading models with weights\n",
    "model_systole = get_model()\n",
    "model_diastole = get_model()\n",
    "model_systole.load_weights(\"weights_systole.hdf5\")\n",
    "model_diastole.load_weights(\"weights_diastole.hdf5\")\n",
    "\n",
    "#load losses to be used as sigma values\n",
    "with open(\"val_losses.txt\", \"rb\") as f:\n",
    "    val_loss_systole = float(f.readline())\n",
    "    val_loss_diastole = float(f.readline())\n",
    "\n",
    "#Predict on test data\n",
    "batch_size = 16\n",
    "pred_systole = model_systole.predict(X_sub_denoised, batch_size = batch_size, verbose = 1)\n",
    "pred_diastole = model_diastole.predict(X_sub_denoised, batch_size = batch_size, verbose = 1)\n",
    "\n",
    "#Get cdf for predictions\n",
    "pred_sys_cdf = get_cdf(pred_systole, val_loss_systole)\n",
    "pred_dia_cdf = get_cdf(pred_diastole, val_loss_diastole)\n",
    "\n",
    "#Accumulate the results for each patient\n",
    "sub_systole = accumulate_studies(ids, pred_sys_cdf)\n",
    "sub_diastole = accumulate_studies(ids, pred_dia_cdf)\n",
    "\n",
    "#generate submission\n",
    "print(\"generating submission file\")\n",
    "fi = csv.reader(open(\"sample_submission_validate.csv\"))\n",
    "f = open(\"sub1.csv\", \"w\") #open a new file in write mode\n",
    "fo = csv.writer(f, lineterminator = \"\\n\")\n",
    "fo.writerow(fi.next())\n",
    "for line in fi:\n",
    "    idx = line[0]\n",
    "    key, target = idx.split(\"_\")\n",
    "    key = int(key)\n",
    "    out = [idx]\n",
    "    if key in sub_systole:\n",
    "        if target == \"Diastole\":\n",
    "            out.extend(list(sub_diastole[key][0]))\n",
    "        else:\n",
    "            out.extend(list(sub_systole[key][0]))\n",
    "    \n",
    "    else:\n",
    "        print(\"missed %s\" %idx)\n",
    "    fo.writerow(out)\n",
    "f.close()\n",
    "print(\"submission file successfully generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating submission file\n",
      "submission file successfully generated\n"
     ]
    }
   ],
   "source": [
    "#Accumulate the results for each patient\n",
    "sub_systole = accumulate_studies(ids, pred_sys_cdf)\n",
    "sub_diastole = accumulate_studies(ids, pred_dia_cdf)\n",
    "\n",
    "#generate submission\n",
    "print(\"generating submission file\")\n",
    "fi = csv.reader(open(\"sample_submission_validate.csv\"))\n",
    "f = open(\"sub1.csv\", \"w\") #open a new file in write mode\n",
    "fo = csv.writer(f, lineterminator = \"\\n\")\n",
    "fo.writerow(fi.next())\n",
    "for line in fi:\n",
    "    idx = line[0]\n",
    "    key, target = idx.split(\"_\")\n",
    "    key = int(key)\n",
    "    out = [idx]\n",
    "    if key in sub_systole:\n",
    "        if target == \"Diastole\":\n",
    "            out.extend(list(sub_diastole[key][0]))\n",
    "        else:\n",
    "            out.extend(list(sub_systole[key][0]))\n",
    "    \n",
    "    else:\n",
    "        print(\"missed %s\" %idx)\n",
    "    fo.writerow(out)\n",
    "f.close()\n",
    "print(\"submission file successfully generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = np.load(\"ids_validate.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_systole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(a, b=2):\n",
    "    return(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
